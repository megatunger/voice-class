{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pickle as pk\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "  y, sr = librosa.load(file_path) # read .wav file\n",
    "  hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "  win_length = math.floor(sr*0.025) # 25ms frame\n",
    "  # mfcc is 12 x T matrix\n",
    "  mfcc = librosa.feature.mfcc(\n",
    "      y, sr, n_mfcc=12, n_fft=1024,\n",
    "      hop_length=hop_length, win_length=win_length)\n",
    "  # substract mean from mfcc --> normalize mfcc\n",
    "  mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "  # delta feature 1st order and 2nd order\n",
    "  delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "  delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "  # X is 36 x T\n",
    "  X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "  # return T x 36 (transpose of X)\n",
    "  return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "  files = os.listdir(data_dir)\n",
    "  mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "  return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=20):\n",
    "  kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "  kmeans.fit(X)\n",
    "  print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "  return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors (30890, 36)\n",
      "centers (20, 36)\n",
      "centers (20, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -6775.8745             +nan\n",
      "         2       -5179.1775       +1596.6970\n",
      "         3       -4526.3625        +652.8150\n",
      "         4       -4038.7151        +487.6474\n",
      "         5       -3890.3442        +148.3708\n",
      "         6       -3832.5451         +57.7992\n",
      "         7       -3798.7416         +33.8034\n",
      "         8       -3771.1157         +27.6260\n",
      "         9       -3745.9441         +25.1716\n",
      "        10       -3720.6368         +25.3074\n",
      "        11       -3707.7267         +12.9100\n",
      "        12       -3702.8488          +4.8779\n",
      "        13       -3700.5976          +2.2512\n",
      "        14       -3699.1717          +1.4259\n",
      "        15       -3698.1186          +1.0530\n",
      "        16       -3697.2020          +0.9166\n",
      "        17       -3696.1378          +1.0642\n",
      "        18       -3694.5887          +1.5491\n",
      "        19       -3692.6344          +1.9543\n",
      "        20       -3690.7721          +1.8623\n",
      "        21       -3688.9114          +1.8607\n",
      "        22       -3686.6461          +2.2653\n",
      "        23       -3684.6909          +1.9552\n",
      "        24       -3683.5553          +1.1356\n",
      "        25       -3682.8235          +0.7318\n",
      "        26       -3682.2062          +0.6173\n",
      "        27       -3681.5991          +0.6072\n",
      "        28       -3680.9015          +0.6975\n",
      "        29       -3679.8622          +1.0394\n",
      "        30       -3677.6787          +2.1834\n",
      "        31       -3671.8545          +5.8242\n",
      "        32       -3660.0798         +11.7747\n",
      "        33       -3649.9230         +10.1568\n",
      "        34       -3642.9963          +6.9267\n",
      "        35       -3630.4682         +12.5280\n",
      "        36       -3619.5293         +10.9390\n",
      "        37       -3596.9292         +22.6000\n",
      "        38       -3568.6197         +28.3095\n",
      "        39       -3558.1451         +10.4747\n",
      "        40       -3554.9909          +3.1542\n",
      "        41       -3554.2594          +0.7315\n",
      "        42       -3553.9572          +0.3022\n",
      "        43       -3553.7574          +0.1998\n",
      "        44       -3553.6080          +0.1494\n",
      "        45       -3553.4930          +0.1150\n",
      "        46       -3553.4036          +0.0894\n",
      "        47       -3553.3336          +0.0700\n",
      "        48       -3553.2785          +0.0551\n",
      "        49       -3553.2347          +0.0438\n",
      "        50       -3553.1995          +0.0352\n",
      "        51       -3553.1710          +0.0285\n",
      "        52       -3553.1475          +0.0235\n",
      "        53       -3553.1280          +0.0195\n",
      "        54       -3553.1115          +0.0165\n",
      "        55       -3553.0974          +0.0141\n",
      "        56       -3553.0852          +0.0122\n",
      "        57       -3553.0745          +0.0107\n",
      "        58       -3553.0649          +0.0095\n",
      "         1      -21559.8141             +nan\n",
      "         2      -12997.9071       +8561.9070\n",
      "         3      -11742.1962       +1255.7109\n",
      "         4      -11330.5028        +411.6934\n",
      "         5      -11246.2990         +84.2037\n",
      "         6      -11221.0584         +25.2406\n",
      "         7      -11209.2786         +11.7798\n",
      "         8      -11203.1666          +6.1120\n",
      "         9      -11199.7591          +3.4075\n",
      "        10      -11197.2541          +2.5049\n",
      "        11      -11193.4699          +3.7842\n",
      "        12      -11181.3372         +12.1327\n",
      "        13      -11113.2415         +68.0956\n",
      "        14      -10967.8532        +145.3884\n",
      "        15      -10948.7339         +19.1192\n",
      "        16      -10947.8620          +0.8720\n",
      "        17      -10946.9802          +0.8817\n",
      "        18      -10946.0256          +0.9546\n",
      "        19      -10945.5259          +0.4997\n",
      "        20      -10945.3110          +0.2149\n",
      "        21      -10945.1682          +0.1428\n",
      "        22      -10945.0357          +0.1325\n",
      "        23      -10944.8947          +0.1410\n",
      "        24      -10944.7321          +0.1627\n",
      "        25      -10944.5301          +0.2019\n",
      "        26      -10944.2595          +0.2707\n",
      "        27      -10943.8644          +0.3951\n",
      "        28      -10943.2290          +0.6354\n",
      "        29      -10942.0856          +1.1434\n",
      "        30      -10939.7783          +2.3073\n",
      "        31      -10935.0321          +4.7461\n",
      "        32      -10926.6891          +8.3430\n",
      "        33      -10914.0598         +12.6293\n",
      "        34      -10899.1080         +14.9517\n",
      "        35      -10890.3847          +8.7233\n",
      "        36      -10887.8216          +2.5631\n",
      "        37      -10887.0316          +0.7900\n",
      "        38      -10886.7357          +0.2958\n",
      "        39      -10886.5853          +0.1505\n",
      "        40      -10886.4713          +0.1139\n",
      "        41      -10886.3601          +0.1112\n",
      "        42      -10886.2426          +0.1175\n",
      "        43      -10886.1198          +0.1228\n",
      "        44      -10885.9976          +0.1222\n",
      "        45      -10885.8840          +0.1136\n",
      "        46      -10885.7860          +0.0980\n",
      "        47      -10885.7075          +0.0785\n",
      "        48      -10885.6486          +0.0589\n",
      "        49      -10885.6067          +0.0419\n",
      "        50      -10885.5778          +0.0289\n",
      "        51      -10885.5581          +0.0197\n",
      "        52      -10885.5446          +0.0135\n",
      "        53      -10885.5351          +0.0095\n",
      "         1      -23156.3794             +nan\n",
      "         2      -14848.2335       +8308.1459\n",
      "         3      -14033.5181        +814.7154\n",
      "         4      -13781.5658        +251.9523\n",
      "         5      -13081.7779        +699.7880\n",
      "         6      -12407.2956        +674.4823\n",
      "         7      -12364.4730         +42.8225\n",
      "         8      -12336.1312         +28.3418\n",
      "         9      -12313.5658         +22.5654\n",
      "        10      -12295.0254         +18.5404\n",
      "        11      -12273.9020         +21.1233\n",
      "        12      -12260.1672         +13.7348\n",
      "        13      -12236.2994         +23.8678\n",
      "        14      -12196.1985         +40.1009\n",
      "        15      -12158.6442         +37.5543\n",
      "        16      -12149.3954          +9.2488\n",
      "        17      -12146.3601          +3.0353\n",
      "        18      -12145.0312          +1.3289\n",
      "        19      -12143.6630          +1.3682\n",
      "        20      -12140.8117          +2.8513\n",
      "        21      -12138.6525          +2.1592\n",
      "        22      -12138.0547          +0.5978\n",
      "        23      -12137.7642          +0.2904\n",
      "        24      -12137.3205          +0.4437\n",
      "        25      -12136.4303          +0.8902\n",
      "        26      -12134.9673          +1.4630\n",
      "        27      -12133.9174          +1.0499\n",
      "        28      -12133.7038          +0.2135\n",
      "        29      -12133.6640          +0.0399\n",
      "        30      -12133.6498          +0.0141\n",
      "        31      -12133.6425          +0.0073\n",
      "         1       -8000.6218             +nan\n",
      "         2       -5571.7506       +2428.8712\n",
      "         3       -4925.8680        +645.8826\n",
      "         4       -4593.6264        +332.2416\n",
      "         5       -4412.6054        +181.0209\n",
      "         6       -4322.1192         +90.4862\n",
      "         7       -4242.0426         +80.0766\n",
      "         8       -4200.3149         +41.7277\n",
      "         9       -4167.3535         +32.9614\n",
      "        10       -4134.8834         +32.4701\n",
      "        11       -4111.6926         +23.1908\n",
      "        12       -4082.9640         +28.7285\n",
      "        13       -4048.0519         +34.9121\n",
      "        14       -4030.6930         +17.3589\n",
      "        15       -4017.8443         +12.8487\n",
      "        16       -4008.3545          +9.4898\n",
      "        17       -4001.7643          +6.5902\n",
      "        18       -3995.8533          +5.9110\n",
      "        19       -3992.6506          +3.2026\n",
      "        20       -3990.4051          +2.2455\n",
      "        21       -3988.0790          +2.3261\n",
      "        22       -3985.6169          +2.4621\n",
      "        23       -3983.1495          +2.4674\n",
      "        24       -3980.6747          +2.4749\n",
      "        25       -3978.4766          +2.1981\n",
      "        26       -3976.6140          +1.8626\n",
      "        27       -3975.1153          +1.4987\n",
      "        28       -3974.0345          +1.0808\n",
      "        29       -3973.2420          +0.7925\n",
      "        30       -3972.5935          +0.6485\n",
      "        31       -3971.7761          +0.8173\n",
      "        32       -3970.4619          +1.3142\n",
      "        33       -3969.5381          +0.9238\n",
      "        34       -3969.1824          +0.3557\n",
      "        35       -3968.9995          +0.1829\n",
      "        36       -3968.8783          +0.1212\n",
      "        37       -3968.7881          +0.0902\n",
      "        38       -3968.7062          +0.0819\n",
      "        39       -3968.5675          +0.1387\n",
      "        40       -3968.1347          +0.4328\n",
      "        41       -3967.1751          +0.9597\n",
      "        42       -3966.4973          +0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        43       -3966.3629          +0.1344\n",
      "        44       -3966.3401          +0.0228\n",
      "        45       -3966.3301          +0.0100\n",
      "         1      -30889.1832             +nan\n",
      "         2      -19416.3474      +11472.8357\n",
      "         3      -17713.4451       +1702.9024\n",
      "         4      -17301.1787        +412.2664\n",
      "         5      -17130.3278        +170.8509\n",
      "         6      -17032.4956         +97.8322\n",
      "         7      -16927.9252        +104.5703\n",
      "         8      -16804.0524        +123.8728\n",
      "         9      -16718.2190         +85.8334\n",
      "        10      -16695.8515         +22.3675\n",
      "        11      -16676.5061         +19.3454\n",
      "        12      -16649.3468         +27.1593\n",
      "        13      -16625.4067         +23.9402\n",
      "        14      -16608.1320         +17.2746\n",
      "        15      -16597.3784         +10.7536\n",
      "        16      -16590.5675          +6.8109\n",
      "        17      -16585.7154          +4.8521\n",
      "        18      -16582.1551          +3.5603\n",
      "        19      -16579.5050          +2.6500\n",
      "        20      -16577.4752          +2.0298\n",
      "        21      -16575.8598          +1.6154\n",
      "        22      -16574.4173          +1.4425\n",
      "        23      -16572.4779          +1.9394\n",
      "        24      -16570.1961          +2.2818\n",
      "        25      -16568.8322          +1.3638\n",
      "        26      -16567.9752          +0.8570\n",
      "        27      -16567.2669          +0.7084\n",
      "        28      -16566.6336          +0.6332\n",
      "        29      -16566.1475          +0.4862\n",
      "        30      -16565.8117          +0.3357\n",
      "        31      -16565.5658          +0.2459\n",
      "        32      -16565.3670          +0.1988\n",
      "        33      -16565.1952          +0.1718\n",
      "        34      -16565.0399          +0.1553\n",
      "        35      -16564.8939          +0.1460\n",
      "        36      -16564.7510          +0.1430\n",
      "        37      -16564.6042          +0.1467\n",
      "        38      -16564.4406          +0.1637\n",
      "        39      -16564.2138          +0.2268\n",
      "        40      -16563.7308          +0.4830\n",
      "        41      -16562.6241          +1.1067\n",
      "        42      -16561.4918          +1.1323\n",
      "        43      -16560.8657          +0.6262\n",
      "        44      -16560.5141          +0.3516\n",
      "        45      -16560.2382          +0.2759\n",
      "        46      -16559.9255          +0.3126\n",
      "        47      -16559.4904          +0.4351\n",
      "        48      -16558.7967          +0.6937\n",
      "        49      -16557.5368          +1.2600\n",
      "        50      -16554.8604          +2.6764\n",
      "        51      -16547.8447          +7.0157\n",
      "        52      -16520.3554         +27.4893\n",
      "        53      -16405.5317        +114.8238\n",
      "        54      -16334.2608         +71.2709\n",
      "        55      -16281.0394         +53.2213\n",
      "        56      -16197.9641         +83.0754\n",
      "        57      -16089.5841        +108.3799\n",
      "        58      -15867.7076        +221.8765\n",
      "        59      -15727.3361        +140.3715\n",
      "        60      -15721.8858          +5.4503\n",
      "        61      -15712.8312          +9.0546\n",
      "        62      -15646.0275         +66.8037\n",
      "        63      -15236.7527        +409.2747\n",
      "        64      -15028.7881        +207.9646\n",
      "        65      -15000.2084         +28.5797\n",
      "        66      -14998.6223          +1.5861\n",
      "        67      -14998.3812          +0.2411\n",
      "        68      -14998.1612          +0.2200\n",
      "        69      -14997.8993          +0.2619\n",
      "        70      -14997.5693          +0.3300\n",
      "        71      -14997.0664          +0.5029\n",
      "        72      -14996.2173          +0.8491\n",
      "        73      -14995.1498          +1.0675\n",
      "        74      -14994.0289          +1.1210\n",
      "        75      -14992.8118          +1.2171\n",
      "        76      -14991.7429          +1.0689\n",
      "        77      -14990.8608          +0.8821\n",
      "        78      -14989.6080          +1.2528\n",
      "        79      -14982.5347          +7.0733\n",
      "        80      -14912.4120         +70.1227\n",
      "        81      -14897.0244         +15.3876\n",
      "        82      -14896.9777          +0.0467\n",
      "        83      -14896.9755          +0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing and Labeling\n",
      "==================================\n",
      "test_toi\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  1.0 ,true:  11 ,total_word:  11\n",
      "==================================\n",
      "test_nguoi\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.6363636363636364 ,true:  7 ,total_word:  11\n",
      "==================================\n",
      "test_hai\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.9090909090909091 ,true:  10 ,total_word:  11\n",
      "==================================\n",
      "test_co_the\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.8 ,true:  12 ,total_word:  15\n",
      "==================================\n",
      "test_benh_nhan\n",
      "==================================\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.7857142857142857 ,true:  11 ,total_word:  14\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    class_names = [\"toi\", \"hai\", \"nguoi\", \"benh_nhan\", \"co_the\", \"test_toi\", \"test_nguoi\", \"test_hai\", \"test_co_the\", \"test_benh_nhan\"]\n",
    "    dataset = {}\n",
    "    train_dataset = {}\n",
    "    for cname in class_names:\n",
    "        dataset[cname] = get_class_data(os.path.join(\"train\", cname))\n",
    "        if cname[:4] != \"test\":\n",
    "#         print(f\"Load {cname} dataset to train\")\n",
    "            train_dataset[cname] = get_class_data(os.path.join(\"train\", cname))\n",
    "\n",
    "#   # Get all vectors in the datasets\n",
    "#   all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "#   print(\"vectors\", all_vectors.shape)\n",
    "#   # Run K-Means algorithm to get clusters\n",
    "#   kmeans = clustering(all_vectors)\n",
    "#   print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "    all_train_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in train_dataset.items()], axis=0)\n",
    "    print(\"vectors\", all_train_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "    kmeans = clustering(all_train_vectors)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "    models = {}\n",
    "    for cname in class_names:\n",
    "        class_vectors = dataset[cname]\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['cname'] = [O^1, ... O^R]\n",
    "# O^r = (c1, c2, ... ct, ... cT)\n",
    "# O^r size T x 1\n",
    "        dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "\n",
    "# =================================================================\n",
    "# toi |t|~|o|~|i|\n",
    "        if cname == \"toi\":\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "              n_components=9, init_params='e', params='ste', verbose=True, n_iter= 1000\n",
    "            ) \n",
    "            hmm.startprob_ = np.array([0.6, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "            hmm.transmat_ = np.array([\n",
    "                [0.6, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.6, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.6, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.6, 0.3, 0.1, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.6, 0.3, 0.1, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.3, 0.1, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.3, 0.1],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.4],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "            ])\n",
    "        # =================================================================\n",
    "#         nguoi |ng|~|uo|~|i|\n",
    "        if cname == \"nguoi\":\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "              n_components=15, init_params='e', params='ste', verbose=True, n_iter= 1000\n",
    "            )\n",
    "            hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "            hmm.transmat_ = np.array([\n",
    "                [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "              ])\n",
    "\n",
    "        # =================================================================\n",
    "        # hai |h|~|a|~|i|\n",
    "        if cname == \"hai\":\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "              n_components=9, init_params='e', params='ste', verbose=True, n_iter= 1000\n",
    "            )\n",
    "            hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "            hmm.transmat_ = np.array([\n",
    "                [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "              ])\n",
    "\n",
    "        # =================================================================\n",
    "        # co_the |c|~|o|~|silent|~|t|~|h|~|e| \n",
    "        if cname == \"co_the\":\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "                n_components=21, init_params='e', params='ste', verbose=True, n_iter= 1000\n",
    "            )\n",
    "            hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "            hmm.transmat_ = np.array([\n",
    "                [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "            ])\n",
    "\n",
    "        # =================================================================\n",
    "        # benh_nhan |b|~|e|~|nh|~|silent|~|nh|~|a|~|n| \n",
    "        if cname == \"benh_nhan\":\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "                n_components=21, init_params='e', params='ste', verbose=True, n_iter= 1000\n",
    "            )\n",
    "            hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "            hmm.transmat_ = np.array([\n",
    "                [0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],    \n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "            ])\n",
    "\n",
    "        if cname[:4] != 'test':\n",
    "          X = np.concatenate(dataset[cname])\n",
    "          lengths = list([len(x) for x in dataset[cname]])\n",
    "        #       print(\"training class\", cname)\n",
    "        #       print(X.shape, lengths, len(lengths))\n",
    "          hmm.fit(X, lengths=lengths)\n",
    "          models[cname] = hmm\n",
    "        #       print(\"Training done\")\n",
    "\n",
    "    print(\"Testing and Labeling\")\n",
    "    for true_cname in class_names:\n",
    "        if true_cname[:4] == \"test\":\n",
    "            print(\"==================================\")\n",
    "            print(true_cname)\n",
    "            print(\"==================================\")\n",
    "\n",
    "            lname = true_cname[5:]\n",
    "            totalWord = 0\n",
    "            true = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            for O in dataset[true_cname]:\n",
    "                totalWord += 1\n",
    "                scores = {}\n",
    "                for cname, model in models.items():\n",
    "                    if cname[:4] != \"test\":\n",
    "                        score = model.score(O, [len(O)])\n",
    "                        scores[cname] = score\n",
    "#                 print(scores)\n",
    "                srt = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            #         print(srt[0])\n",
    "                if srt[0][0] == lname:\n",
    "                    true += 1\n",
    "            accuracy = true/totalWord\n",
    "            print(\"--------------------------------------------\")\n",
    "            print(\"!note: test_folder must contain wavs that it records exactly the word which be trained\")\n",
    "            print(\"accuracy: \", accuracy, \",true: \", true, \",total_word: \", totalWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open(\"m.pkl\", \"wb\") as file:\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
